
# Titanic - Machine Learning from Disaster (Parte 1)


## Introdu√ß√£o

O naufr√°gio do Titanic √© um dos naufr√°gios mais infames da hist√≥ria. Em 15 de abril de 1912, durante sua viagem inaugural, o RMS Titanic, amplamente considerado ‚Äúinafund√°vel‚Äù, afundou ap√≥s colidir com um iceberg. Infelizmente, n√£o havia botes salva-vidas suficientes para todos a bordo, resultando na morte de 1.502 dos 2.224 passageiros e tripulantes.

Embora houvesse algum elemento de sorte envolvido na sobreviv√™ncia, parece que alguns grupos de pessoas tinham maior probabilidade de sobreviver do que outros.



## Decri√ß√£o do Projeto

Esse projeto trata-se de uma competi√ß√£o que ocorre em um dos sites mais famosos dentro da comunidade de dados, o **Kaggle**.

Neste projeto, ser√° construido um modelo preditivo que responda √† pergunta: 
- ‚ÄúQue tipos de pessoas t√™m maior probabilidade de sobreviver ao naufr√°gio do Titanic?‚Äù 
    - usando dados de passageiros (ou seja, nome, idade, sexo, classe socioecon√¥mica, etc), tentaremos prever.

Os dados foram divididos em dois grupos:

- **conjunto de treinamento** (train.csv)
    - 890 registros 
    - Aproximadamente: 70%
    - Esse conjunto √© usado para realizar o treinamento dos modelos e a valida√ß√£o.
- **conjunto de teste** (test.csv)
    - 417 registros 
    - Aproximadamente: 30%
    - Esse conjunto √© usado para de fato testar a efic√°cia do classificador treinado
        - A resposta √© obtida depois de submetida na plataforma do Kaggle.

O **conjunto de treinamento** deve ser usado para construir o modelo de aprendizado de m√°quina. Para o conjunto de treinamento, foi fornecido o resultado (tamb√©m conhecido como ‚Äúverdade b√°sica‚Äù) para cada passageiro, onde √© indicado quem sobreviveu (1) e quem n√£o sobreviveu (0) . O modelo ser√° baseado em ‚Äúcaracter√≠sticas‚Äù presentes na base de dados.

O **conjunto de testes** ser√° usado para ver o desempenho do modelo em dados n√£o vistos. Para o conjunto de testes, n√£o ser√° fornecido as informa√ß√µes dos passageiros que sobreviveram ou n√£o. O trabalho √© justamente prever esses resultados, onde para cada passageiro no conjunto de teste, ser√° usado o modelo treinado para prever se eles sobreviveram ou n√£o ao naufr√°gio do Titanic.

- Ser√° analisado a acur√°cia do modelo, para determinar se o resultado √© satisfat√≥rio ou n√£o.

## Objetivo

Essa √© a Parte 1 de um conjunto de an√°lises feitas sobre este dataset. Em cada uma das partes, ser√£o abordados m√©todos, an√°lises ou tratativas de dados distintas, com o objetivo de aumentar a acur√°cia do resultado final.

## Metodologia

- Dado a quantidade de informa√ß√µes que o dataset gera, iremos fazer uma an√°lise exploratoria nos dados, observando se ocorre uma melhora nos resultados a partir do momento que entramos em contato com mais m√©tricas
- Nessa parte 1 foi feito:

    - **Importa√ß√£o da base**
    - **Uso ydata-profiling (ideia geral dos dados)**
    - **Limpeza de dados**
    - **Sele√ß√£o e treinamento ds modelos para classifica√ß√£o**
        - √Årvore de classifica√ß√£o
        - Classifica√ß√£o dos vizinhos mais pr√≥ximos (KNN)
        - Regress√£o Log√≠stica
    - **Avalia√ß√£o dos modelos**
        - Acur√°cia
        - Matriz de Confus√£o
    - **Realizando a previs√£o dos dados de Teste**
        - Submiss√£o do projeto para a plataforma Kaggle, que √© a responsavel por verificar a acur√°cia final com os dados de teste.

- A an√°lise foi realizada em um arquivo **Jupyter Notebook**, ent√£o algumas explica√ß√µes se encontram ao decorrer do arquivo.

- No diretorio tamb√©m se encontra uma pasta **'dados'** com:
    - O conjunto de teste (*test.csv*) e o conjunto de treino (*train.csv*).
    - O arquivo da biblioteca (*ydata-profiling*) que auxilia na an√°lise explorat√≥ria (*titanic_treino.html*).
    - E o arquivo com os dados que foram submetidos para an√°lise no Kaggle (*base_envio.csv*).




## Conclus√£o

Neste projeto, que representa a Parte 1 de uma s√©rie de an√°lises do dataset Titanic, realizamos diversas etapas para construir e avaliar modelos preditivos com o objetivo de determinar os fatores que influenciam a sobreviv√™ncia dos passageiros do Titanic. Atrav√©s da importa√ß√£o e limpeza dos dados, do uso de ferramentas de an√°lise explorat√≥ria como o ydata-profiling, e da implementa√ß√£o de v√°rios modelos de classifica√ß√£o (√Årvore de Decis√£o, K-Nearest Neighbors, Regress√£o Log√≠stica), conseguimos obter uma vis√£o inicial das caracter√≠sticas mais relevantes e da performance dos modelos.

Os principais pontos abordados incluem:

- **Importa√ß√£o e limpeza de dados:** Garantimos que os dados estavam prontos para an√°lise, removendo inconsist√™ncias e preenchendo valores ausentes.

- **An√°lise explorat√≥ria:** Utilizamos o ydata-profiling para obter uma vis√£o geral dos dados e identificar padr√µes iniciais.
- **Sele√ß√£o e treinamento de modelos:** Implementamos e treinamos modelos de classifica√ß√£o, ajustando par√¢metros e avaliando suas performances.
- **Avalia√ß√£o dos modelos:** Medimos a acur√°cia e analisamos as matrizes de confus√£o para entender melhor a efic√°cia dos modelos.
- **Previs√£o e submiss√£o:** Aplicamos o modelo aos dados de teste e submetemos as previs√µes ao Kaggle para avalia√ß√£o final.

Com esta abordagem inicial, conseguimos estabelecer uma linha de base para a acur√°cia dos nossos modelos. Em partes subsequentes deste projeto, continuaremos a explorar diferentes t√©cnicas e tratamentos de dados para melhorar a performance preditiva.

O c√≥digo e as an√°lises detalhadas podem ser encontrados no arquivo Jupyter Notebook inclu√≠do neste reposit√≥rio. √Ä medida que avan√ßamos para as pr√≥ximas partes da s√©rie, esperamos refinar ainda mais nossos m√©todos e obter insights mais profundos sobre os fatores que influenciam a sobreviv√™ncia no desastre do Titanic.





## üõ† Ferramentas
- Python 
- Bibliotecas 
    - Pandas
    - YData Profiling
    - Scikit Learn 
    - Seaborn
    - Matplotlib
    



## Autores

- [@pedrohspassos](https://github.com/pedrohspassos)



## Refer√™ncias


 - [Ferramenta de an√°lise explorat√≥ria](https://github.com/ydataai/ydata-profiling)
 - [√Årvore de Decis√£o | scikit-learn](https://scikit-learn.org/stable/modules/tree.html#classification)
 - [Classifica√ß√£o dos vizinhos mais pr√≥ximos (KNN) | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)
 - [Regress√£o Log√≠stica | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)
- [Acur√°cia | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)
- [Matriz de Confus√£o | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)

