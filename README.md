
# Titanic - Machine Learning from Disaster 

- Abaixo se encontra um preview do hist√≥rico obtido durante o desenvolvimento do projeto:

![img_resultado](https://github.com/user-attachments/assets/f3377bd0-77ce-4aea-8825-06649091a1b2)


## Introdu√ß√£o

O naufr√°gio do Titanic √© um dos naufr√°gios mais infames da hist√≥ria. Em 15 de abril de 1912, durante sua viagem inaugural, o RMS Titanic, amplamente considerado ‚Äúinafund√°vel‚Äù, afundou ap√≥s colidir com um iceberg. Infelizmente, n√£o havia botes salva-vidas suficientes para todos a bordo, resultando na morte de 1.502 dos 2.224 passageiros e tripulantes.

Embora houvesse algum elemento de sorte envolvido na sobreviv√™ncia, parece que alguns grupos de pessoas tinham maior probabilidade de sobreviver do que outros.



## Decri√ß√£o do Projeto

Esse projeto trata-se de uma competi√ß√£o que ocorre em um dos sites mais famosos dentro da comunidade de dados, o **Kaggle**.

Os dados foram divididos em dois grupos:

- **conjunto de treinamento** (train.csv)
    - 890 registros 
    - Aproximadamente: 70%
    - Esse conjunto √© usado para realizar o treinamento dos modelos e a valida√ß√£o.
- **conjunto de teste** (test.csv)
    - 417 registros 
    - Aproximadamente: 30%
    - Esse conjunto √© usado para de fato testar a efic√°cia do classificador treinado
        - A resposta √© obtida depois de submetida na plataforma do Kaggle.

O **conjunto de treinamento** deve ser usado para construir o modelo de aprendizado de m√°quina. Para o conjunto de treinamento, foi fornecido o resultado (tamb√©m conhecido como ‚Äúverdade b√°sica‚Äù) para cada passageiro, onde √© indicado quem sobreviveu (1) e quem n√£o sobreviveu (0) . O modelo ser√° baseado em ‚Äúcaracter√≠sticas‚Äù presentes na base de dados.

O **conjunto de testes** ser√° usado para ver o desempenho do modelo em dados n√£o vistos. Para o conjunto de testes, n√£o ser√° fornecido as informa√ß√µes dos passageiros que sobreviveram ou n√£o. O trabalho √© justamente prever esses resultados, onde para cada passageiro no conjunto de teste, ser√° usado o modelo treinado para prever se eles sobreviveram ou n√£o ao naufr√°gio do Titanic.

- Ser√° analisado a acur√°cia do modelo, para determinar se o resultado √© satisfat√≥rio ou n√£o.

## Objetivo

Desenvolver um modelo que conseguisse acertar quais passageiros sobreviveram ou n√£o ao na√∫fragio do Titanic. Para isso, aquele que obtivesse a maior **acur√°cia** seria o escolhido.

## Etapas

- ## [Etapa 1 - Primeiro modelo](https://github.com/pedrohspassos/predicted-survivors-titanic/blob/main/analise_titanic_parte1.ipynb)
    - Nesse etapa foi feito apenas o b√°sico para conseguir verificar qual seria o resultado sem fazer nenhum tratamento nem engenharia dos dados
      - Foi visualizado um resumo da base utilizando o [ydata-profiling](https://github.com/ydataai/ydata-profiling), biblioteca capaz de gerar com poucas linhas toda a descri√ß√£o do nosso dataset
      - Tamb√©m foi elimido as colunas com elevada cardinalidade, foi tratado os valores vazios utilizando a m√©dia e a moda das vari√°veis e foi eliminado todas as colunas de texto
      - Foram criados modelos utilizando 3 algoritmos: √Årvore de Classifica√ß√£o, KNN e Regress√£o Log√≠stica, nos quais foram avaliados utilizando a acur√°cia e a matriz de confus√£o
  - **O score p√∫blico retornado pelo Kaggle foi: 0,66746**
    
- ## [Etapa 2 - Tratando as vari√°veis de texto](https://github.com/pedrohspassos/predicted-survivors-titanic/blob/main/analise_titanic_parte2.ipynb)
    - Na segunda etapa o foco principal foi tratar as vari√°veis de texto para que fosse poss√≠vel utilizar todas as vari√°veis no modelo
        - Para fazer esse tratamento, utilizamos **lambda function** e **OneHotEncoder**
    - Foram utilizados os mesmos modelos apresentados anteriormente
    - **O score p√∫blico retornado pelo Kaggle foi: 0,76555**

- ## [Etapa 3 - Aprofundando no neg√≥cio e melhorando os tratamentos dos dados](https://github.com/pedrohspassos/predicted-survivors-titanic/blob/main/analise_titanic_parte3.ipynb)
    - Nessa terceira etapa o grande objetivo era entender melhor os dados para fazer um melhor tratamento e tentar melhorar o resultado obtido anteriormente
    - Logo, foi feito:
        - O **ajuste na escala dos dados para as colunas Age e Fare**
        - O entendimento melhor sobre as colunas **SibSp** (n¬∫ de irm√£os/c√¥njuges a bordo do Titanic) e **Parch** (n¬∫ de pais/filhos a bordo do Titanic) e a cria√ß√£o de **duas novas colunas: total de familiares a bordo do navio e se o passageiro estava sozinho ou n√£o**
        - Por fim, foi analisado a **correla√ß√£o de todas as vari√°veis para selecionar aquelas que mais faziam sentido para o modelo**
    - Foram utilizados os mesmos modelos apresentados anteriormente
    - **O score p√∫blico retornado pelo Kaggle foi: 0,77033**
      
- ## [Etapa 4 - Selecionando outros algoritmos para fazer a previs√£o](https://github.com/pedrohspassos/predicted-survivors-titanic/blob/main/analise_titanic_parte4.ipynb)
    - Nessa etapa, foram mantidas todas as colunas (incluindo SibSp e Parch) e foram usados novos algoritmos para verificar o resultado do modelo
    - Os algoritmos utilizados nessa etapa s√£o **RandomForest , MLPCLassifier (Redes Neurais) e Regress√£o Log√≠stica** (mantida devido seus bons resultados ao decorrer das etapas)
    - O MLPClassifier (um algoritmo de Redes Neurais) obteve a maior acur√°cia nos dados de valida√ß√£o entre todos os modelos vistos at√© anteriormente, por√©m ao usar esse modelo nos dados de teste (submetidos no Kaggle) o resultado foi pior que na etapa 3, mostrando que provavelmente tivemos um **overfitting do nosso modelo**
    - **O score p√∫blico retornado pelo Kaggle foi: 0,69856**
      
- ## [Etapa 5 - Utilizando o GridSearchCV e determinando os melhores par√¢metros](https://github.com/pedrohspassos/predicted-survivors-titanic/blob/main/analise_titanic_parte5.ipynb)
    - Foi utilizado o **GridSearchCV** para determinar os melhores par√¢metros para os 3 modelos que foram utilizados na etapa anterior
    - Nesse caso, o modelo escolhido foi aquele que utilizava o **RandomForest** e o resultado melhorou consideravalmente em rela√ß√£o a etapa 4 e foi melhor que na etapa 3
    -  - **O score p√∫blico retornado pelo Kaggle foi: 0,78229**






## Conclus√£o







## üõ† Ferramentas
- Python 
- Bibliotecas 
    - Pandas
    - YData Profiling
    - Scikit Learn 
    - Seaborn
    - Matplotlib
    



## Autores

- [@pedrohspassos](https://github.com/pedrohspassos)



## Refer√™ncias


 - [Ferramenta de an√°lise explorat√≥ria](https://github.com/ydataai/ydata-profiling)
 - [√Årvore de Decis√£o | scikit-learn](https://scikit-learn.org/stable/modules/tree.html#classification)
 - [Classifica√ß√£o dos vizinhos mais pr√≥ximos (KNN) | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)
 - [Regress√£o Log√≠stica | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)
- [Acur√°cia | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)
- [Matriz de Confus√£o | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)

